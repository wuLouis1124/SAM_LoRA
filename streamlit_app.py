import streamlit as st
import numpy as np
import torch
import matplotlib.pyplot as plt
from PIL import Image
from streamlit_drawable_canvas import st_canvas
from segment_anything import sam_model_registry, SamPredictor
from scipy.ndimage import binary_erosion, binary_dilation
import time  # æ–°å¢å¯¼å…¥timeåº“

# åŠ è½½ç›®æ ‡å›¾ç‰‡ï¼Œå¹¶è·å–å…¶å°ºå¯¸
target_image_path = "000068.jpg"  # ç›®æ ‡å›¾ç‰‡çš„è·¯å¾„
target_image = Image.open(target_image_path)
target_width, target_height = target_image.size  # è·å–ç›®æ ‡å›¾ç‰‡çš„å®½åº¦å’Œé«˜åº¦

# å®šä¹‰ç¼©æ”¾å‡½æ•°ï¼Œå°†å›¾ç‰‡ç›´æ¥ç¼©æ”¾è‡³ç›®æ ‡å¤§å°ï¼ˆä¸ä¿ç•™åŸæ¯”ä¾‹ï¼‰
def resize_image_to_target(image, target_width, target_height):
    """
    å°†è¾“å…¥å›¾ç‰‡ç›´æ¥ç¼©æ”¾è‡³ç›®æ ‡å›¾ç‰‡çš„å®½åº¦å’Œé«˜åº¦ï¼Œä¸ä¿ç•™åŸå®½é«˜æ¯”ã€‚
    :param image: è¾“å…¥çš„PILå›¾ç‰‡å¯¹è±¡
    :param target_width: ç›®æ ‡å›¾ç‰‡çš„å®½åº¦
    :param target_height: ç›®æ ‡å›¾ç‰‡çš„é«˜åº¦
    :return: ç¼©æ”¾åçš„Tensorå¯¹è±¡ï¼Œæ ¼å¼ä¸º (B, C, H, W)
    """
    # ç›´æ¥ç¼©æ”¾å›¾ç‰‡åˆ°ç›®æ ‡å®½åº¦å’Œé«˜åº¦
    resized_image = image.resize((target_width, target_height), Image.Resampling.LANCZOS)

    return resized_image

# åŠ è½½SAMæ¨¡å‹
@st.cache_resource
def load_sam_model():
    model_type = "vit_h"
    sam_checkpoint = "sam_vit_h_4b8939.pth"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
    sam.to(device=device)
    predictor = SamPredictor(sam)
    return predictor

# æ˜¾ç¤ºåˆ†å‰²è’™ç‰ˆå’Œå‘å…‰è¾¹æ¡†
def show_mask(mask, image, ax):
    color = np.random.random(3)  # éšæœºç”Ÿæˆé¢œè‰²
    h, w = mask.shape[-2:]

    # åˆ›å»ºè’™ç‰ˆå›¾åƒå¹¶åº”ç”¨é¢œè‰²
    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
    img_with_mask = image.copy()

    # åˆ›å»ºé€æ˜çš„è’™ç‰ˆä»¥çªå‡ºæ˜¾ç¤ºè¾¹ç¼˜
    alpha_mask = 0.4  # é€æ˜åº¦
    img_with_mask[mask != 0] = img_with_mask[mask != 0] * (1 - alpha_mask) + mask_image[mask != 0] * (255 * alpha_mask)

    # æå–è’™ç‰ˆçš„è¾¹ç¼˜
    edges = mask.astype(bool) ^ binary_erosion(mask.astype(bool))

    # ç»˜åˆ¶å‘å…‰æ•ˆæœ
    glow_color = (0, 1, 0, 0.5)  # å‘å…‰é¢œè‰²
    glow_width = 5  # å‘å…‰å®½åº¦
    for i in range(1, 4):  # ç»˜åˆ¶å¤šä¸ªè¾¹æ¡†ä»¥æ¨¡æ‹Ÿå‘å…‰
        # åœ¨è¾¹ç¼˜ä¸Šç»˜åˆ¶å‘å…‰æ•ˆæœ
        ax.imshow(edges * (1 - (i * 0.2)), cmap='Greens', alpha=glow_width * 0.2, interpolation='nearest', extent=[0, w, h, 0])

    ax.imshow(img_with_mask)

# æ˜¾ç¤ºæ¡†
def show_box(box, ax):
    x0, y0 = box[0], box[1]
    w, h = box[2] - box[0], box[3] - box[1]
    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))

# SAMåˆ†å‰²é€»è¾‘
def sam_segmentation(image_np, predictor, method, point_coords=None, box_coords=None):
    predictor.set_image(image_np)
    if method == "point" and point_coords is not None:
        input_points = np.array([point_coords])
        input_labels = np.array([1])
        masks, _, _ = predictor.predict(point_coords=input_points, point_labels=input_labels, multimask_output=False)
    elif method == "box" and box_coords is not None:
        box_coords = np.array(box_coords).reshape(-1, 2)
        masks, _, _ = predictor.predict(box=box_coords, multimask_output=False)
    else:
        return None
    return masks[0]

# Streamlit å‰ç«¯å¸ƒå±€
st.set_page_config(layout="wide")

st.title("âœ¨ Segment Anything ğŸœ")
st.info('Let me help generate segments for any of your images. ğŸ˜‰')

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ç”¨äºä¿å­˜åˆ†å‰²æ–¹å¼
if "method" not in st.session_state:
    st.session_state["method"] = "point"
    method = "point"
    
col1, col2 = st.columns([1, 4])

with col1:
    st.header("æç¤ºåˆ†å‰²æ–¹å¼")
    if st.button("é€‰æ‹©Pointæ–¹å¼åˆ†å‰²", key="point_btn", use_container_width=True, icon=":material/my_location:") :
        st.session_state["method"] = "point"
    
    if st.button("é€‰æ‹©Boxæ–¹å¼åˆ†å‰²", key="box_btn", use_container_width=True, icon=":material/indeterminate_question_box:"):
        st.session_state["method"] = "box"

    st.header("æç¤ºåˆ†å‰²æ•°é‡")
    if st.button("single-masked", key="single_masked", use_container_width=True, icon=":material/looks_one:") :
        st.session_state["number"] = "single"
    
    if st.button("multi-masked", key="multi-masked", use_container_width=True, icon=":material/more_horiz:"):
        st.session_state["number"] = "multi"

with col2:
    # ä¸Šä¼ å›¾ç‰‡
    uploaded_file = st.file_uploader("ä¸Šä¼ ä¸€å¼ å›¾ç‰‡", type=["jpg", "png", "jpeg"])
    
    mask = None

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        image = resize_image_to_target(image, target_width, target_height)
        image_np = np.array(image)

        # åŠ è½½ SAM æ¨¡å‹
        predictor = load_sam_model()

        # åˆ›å»ºå·¦å³ä¸¤ä¸ªåˆ—
        img_col1, img_col2 = st.columns(2)

        method = st.session_state["method"]
        if method == "point":
            # æ˜¾ç¤ºä¸Šä¼ çš„å›¾ç‰‡ä½œä¸ºäº¤äº’å›¾ï¼ˆå›¾ç‰‡1ï¼‰
            with img_col1:
                # ç›´æ¥æ˜¾ç¤ºä¸Šä¼ çš„å›¾ç‰‡
                canvas_result = st_canvas(
                    fill_color="rgba(0, 0, 255, 0.3)",  # å¡«å……é¢œè‰²
                    stroke_width=2,
                    background_image=Image.fromarray(image_np),  # æ¯æ¬¡é‡æ–°åŠ è½½åŸå§‹å›¾ç‰‡
                    update_streamlit=True,
                    height=image_np.shape[0],
                    width=image_np.shape[1],
                    drawing_mode="point",  # è®¾ç½®ä¸ºç‚¹å‡»æ¨¡å¼
                    key="canvas",
                )

            # æ•è·ç”¨æˆ·ç‚¹å‡»ä½ç½®å¹¶åªä¿ç•™æœ€æ–°çš„ç‚¹å‡»
            if canvas_result.json_data is not None and len(canvas_result.json_data["objects"]) > 0:
                # åªè·å–æœ€åä¸€ä¸ªç‚¹å‡»çš„åæ ‡
                obj = canvas_result.json_data["objects"][-1]
                point_x = int(obj["left"])
                point_y = int(obj["top"])

                # è·å–åˆ†å‰²ç»“æœ
                mask = sam_segmentation(image_np, predictor, method="point", point_coords=(point_x, point_y))

        elif method == "box":

            # ä½¿ç”¨ Streamlit Drawable Canvas å…è®¸ç”¨æˆ·ç»˜åˆ¶çŸ©å½¢æ¡†
            with img_col1:
                box_canvas = st_canvas(
                    fill_color="rgba(0, 255, 0, 0.1)",  # å¡«å……é¢œè‰²
                    stroke_width=2,
                    background_image=Image.fromarray(image_np),  # æ¯æ¬¡é‡æ–°åŠ è½½åŸå§‹å›¾ç‰‡
                    update_streamlit=True,
                    height=image_np.shape[0],
                    width=image_np.shape[1],
                    drawing_mode="rect",  # è®¾ç½®ä¸ºçŸ©å½¢ç»˜åˆ¶æ¨¡å¼
                    key="box_canvas",
                )

            # è·å–ç”¨æˆ·ç»˜åˆ¶çš„æ¡†åæ ‡å¹¶åªä¿ç•™æœ€æ–°çš„æ¡†
            if box_canvas.json_data is not None and box_canvas.json_data["objects"]:
                # è·å–æœ€åä¸€ä¸ªæ¡†çš„åæ ‡
                obj = box_canvas.json_data["objects"][-1]
                box_x1 = int(obj["left"])
                box_y1 = int(obj["top"])
                box_x2 = box_x1 + int(obj["width"])
                box_y2 = box_y1 + int(obj["height"])

                # è·å–åˆ†å‰²ç»“æœ
                mask = sam_segmentation(image_np, predictor, method="box", box_coords=[box_x1, box_y1, box_x2, box_y2])

        # æ˜¾ç¤ºåˆ†å‰²ç»“æœçš„å›¾ç‰‡ï¼ˆå›¾ç‰‡2ï¼‰
        with img_col2:
            if mask is not None:
                with st.spinner("å›¾ç‰‡2æ­£åœ¨åŠ è½½..."):
                    time.sleep(1)  # å¼ºåˆ¶å»¶è¿Ÿ1ç§’
                    # åˆ›å»ºåˆ†å‰²å¯è§†åŒ–ï¼Œæ¸…é™¤æ—§çš„æ˜¾ç¤ºæœ€æ–°çš„åˆ†å‰²ç»“æœ
                    fig, ax = plt.subplots(figsize=(5, 5), dpi=100)  # è®¾ç½® dpi ä¿æŒä¸€è‡´æ€§
                    ax.imshow(image_np)
                    show_mask(mask, image_np, ax)
                    if method == "box":
                        show_box([box_x1, box_y1, box_x2, box_y2], ax)
                     # å…³é—­åæ ‡è½´å¹¶è°ƒæ•´è¾¹è·
                    ax.axis('off')
                    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # å»é™¤è¾¹ç•Œ

                    # ä½¿ç”¨ bbox_inches='tight' é€‰é¡¹ä»¥ç¡®ä¿æ²¡æœ‰é¢å¤–çš„è¾¹ç¼˜
                    st.pyplot(fig, bbox_inches='tight')
